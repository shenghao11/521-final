# -*- coding: utf-8 -*-
"""nlp_question_answering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L5LYLjMPWwhpZxwcoFuuAtnbYvxtoid9
"""

!pip install transformers[sentencepiece]

!pip install datasets

from transformers import AutoTokenizer,DataCollatorWithPadding,Trainer,TrainingArguments,AutoModelForSequenceClassification
from datasets import load_dataset,load_metric

import pandas as pd

train='/content/chatbot_train.csv'
test='/content/chatbot_test.csv'

df=load_dataset('csv',data_files={'train': train, 'test': test})

train=df['train']
test=df['test']

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased", fast=True)

def tokenizer_map(instance):
  return tokenizer(instance['question'],truncation=True)

tokenized_dataset=train.map(tokenizer_map,batched=True)
tokenized_test=test.map(tokenizer_map,batched=True)

data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

def compute_metrics(eval_preds):
    metric = load_metric("accuracy")
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)

training_args = TrainingArguments(output_dir="saved",per_device_train_batch_size=8)

model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=1000)

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_dataset,
    data_collator=data_collator, 
    eval_dataset=tokenized_dataset,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)

trainer.train()
trainer.save_model()

tokenizer = AutoTokenizer.from_pretrained("./saved")
model = AutoModelForSequenceClassification.from_pretrained("./saved")
model.eval()

import torch
import numpy as np
tex1='give me some information about stopwords'
tex3='what is a language model'
tex2='what are stopwords'
def represent(text):
  tokens = tokenizer.encode(text, add_special_tokens=True)
  input_ids = torch.tensor([tokens])
  outputs = model(input_ids)
  cls_embedding = outputs[0]
# Print the sentence embedding
  return(cls_embedding)
def similarity(text1,text2):
  return torch.cosine_similarity(represent(text1),represent(text2))
print(similarity(tex1,tex2))
print(similarity(tex1,tex3))

